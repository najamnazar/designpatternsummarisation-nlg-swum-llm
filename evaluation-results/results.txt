============================================================
OVERALL ANALYSIS
============================================================

       method  projects_evaluated  classes_evaluated avg_cosine avg_bert_precision avg_bert_recall avg_bert_f1 combined_score cosine_std bert_f1_std
          NLG                   3                150     0.1637             0.8275          0.8567      0.8414         0.5026     0.0776      0.0235
         SWUM                   3                150     0.2452             0.8854          0.8588      0.8715         0.5583     0.0990      0.0168
LLM (Mixtral)                   3                150     0.3365             0.8624          0.8910      0.8763         0.6064     0.1269      0.0173

Detailed Metrics by Method:

NLG
  Projects Evaluated: 3
  Classes Evaluated: 150
  Avg Cosine Similarity: 0.1637
  Avg BERT Precision: 0.8275
  Avg BERT Recall: 0.8567
  Avg BERT F1: 0.8414
  Combined Score: 0.5026

SWUM
  Projects Evaluated: 3
  Classes Evaluated: 150
  Avg Cosine Similarity: 0.2452
  Avg BERT Precision: 0.8854
  Avg BERT Recall: 0.8588
  Avg BERT F1: 0.8715
  Combined Score: 0.5583

LLM (Mixtral) (Mixtral-8x22B)
  Projects Evaluated: 3
  Classes Evaluated: 150
  Avg Cosine Similarity: 0.3365
  Avg BERT Precision: 0.8624
  Avg BERT Recall: 0.8910
  Avg BERT F1: 0.8763
  Combined Score: 0.6064
